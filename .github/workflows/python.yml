env:
  JAI_CODEC_VERSION: 1.1.3
  JAI_CORE_VERSION: 1.1.3
  JAI_IMAGEIO_VERSION: '1.1'
  MAVEN_OPTS: -Dmaven.wagon.httpconnectionManager.ttlSeconds=60
jobs:
  build:
    runs-on: self-hosted
    steps:
    - continue-on-error: true
      uses: actions/checkout@v4
    - continue-on-error: true
      uses: actions/setup-java@v4
      with:
        distribution: zulu
        java-version: '8'
    - continue-on-error: true
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python }}
    - continue-on-error: true
      name: Cache Maven packages
      uses: actions/cache@v3
      with:
        key: ${{ runner.os }}-m2-${{ hashFiles('**/pom.xml') }}
        path: ~/.m2
        restore-keys: ${{ runner.os }}-m2
    - continue-on-error: true
      env:
        SCALA_VERSION: ${{ matrix.scala }}
        SPARK_VERSION: ${{ matrix.spark }}
      run: "SPARK_COMPAT_VERSION=\"3.0\"\nif [ ${SPARK_VERSION:2:1} -gt \"3\" ]; then\n\
        \  SPARK_COMPAT_VERSION=${SPARK_VERSION:0:3}\nfi\nmvn -q clean install -DskipTests\
        \ -Dspark=${SPARK_COMPAT_VERSION} -Dscala=${SCALA_VERSION:0:4} -Dgeotools\n"
    - continue-on-error: true
      env:
        HADOOP_VERSION: ${{ matrix.hadoop }}
        SPARK_VERSION: ${{ matrix.spark }}
      run: 'wget https://archive.apache.org/dist/spark/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz

        wget https://repo.osgeo.org/repository/release/javax/media/jai_core/${JAI_CORE_VERSION}/jai_core-${JAI_CORE_VERSION}.jar

        wget https://repo.osgeo.org/repository/release/javax/media/jai_codec/${JAI_CODEC_VERSION}/jai_codec-${JAI_CODEC_VERSION}.jar

        wget https://repo.osgeo.org/repository/release/javax/media/jai_imageio/${JAI_IMAGEIO_VERSION}/jai_imageio-${JAI_IMAGEIO_VERSION}.jar

        tar -xzf spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz

        mv -v jai_core-${JAI_CORE_VERSION}.jar spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}/jars/

        mv -v jai_codec-${JAI_CODEC_VERSION}.jar spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}/jars/

        mv -v jai_imageio-${JAI_IMAGEIO_VERSION}.jar spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}/jars/

        '
    - continue-on-error: true
      run: sudo apt-get -y install python3-pip python-dev-is-python3
    - continue-on-error: true
      run: sudo pip3 install -U setuptools
    - continue-on-error: true
      run: sudo pip3 install -U wheel
    - continue-on-error: true
      run: sudo pip3 install -U virtualenvwrapper
    - continue-on-error: true
      run: python3 -m pip install pipenv
    - continue-on-error: true
      run: cd python; python3 setup.py build_ext --inplace
    - continue-on-error: true
      env:
        PYTHON_VERSION: ${{ matrix.python }}
        SHAPELY_VERSION: ${{ matrix.shapely }}
        SPARK_VERSION: ${{ matrix.spark }}
      run: "cd python\nif [ \"${SHAPELY_VERSION}\" == \"1\" ]; then\n  echo \"Patching\
        \ Pipfile to use Shapely 1.x\"\n  sed -i 's/^shapely.*$/shapely=\"<2.0.0\"\
        /g' Pipfile\nfi\npipenv --python ${PYTHON_VERSION}\npipenv install pyspark==${SPARK_VERSION}\n\
        pipenv install --dev\npipenv graph\n"
    - continue-on-error: true
      env:
        HADOOP_VERSION: ${{ matrix.hadoop }}
        SPARK_VERSION: ${{ matrix.spark }}
      run: find spark-shaded/target -name sedona-*.jar -exec cp {} spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}/jars/
        \;
    - continue-on-error: true
      env:
        HADOOP_VERSION: ${{ matrix.hadoop }}
        SPARK_VERSION: ${{ matrix.spark }}
      run: (export SPARK_HOME=$PWD/spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION};export
        PYTHONPATH=$SPARK_HOME/python;cd python;pipenv run pytest tests)
    strategy:
      matrix:
        include:
        - hadoop: '3'
          python: '3.10'
          scala: 2.12.8
          shapely: '1'
          spark: 3.5.0
        - hadoop: '3'
          python: '3.10'
          scala: 2.12.8
          spark: 3.5.0
        - hadoop: '3'
          python: '3.9'
          scala: 2.12.8
          spark: 3.5.0
        - hadoop: '3'
          python: '3.8'
          scala: 2.12.8
          spark: 3.5.0
        - hadoop: '3'
          python: '3.10'
          scala: 2.12.8
          spark: 3.4.0
        - hadoop: '3'
          python: '3.9'
          scala: 2.12.8
          spark: 3.4.0
        - hadoop: '3'
          python: '3.8'
          scala: 2.12.8
          spark: 3.4.0
        - hadoop: '3'
          python: '3.7'
          scala: 2.12.8
          spark: 3.4.0
        - hadoop: '3'
          python: '3.7'
          scala: 2.12.8
          shapely: '1'
          spark: 3.4.0
        - hadoop: '3'
          python: '3.8'
          scala: 2.12.8
          spark: 3.3.0
        - hadoop: '2.7'
          python: '3.7'
          scala: 2.12.8
          spark: 3.2.0
        - hadoop: '2.7'
          python: '3.7'
          scala: 2.12.8
          spark: 3.1.2
        - hadoop: '2.7'
          python: '3.7'
          scala: 2.12.8
          spark: 3.0.3
name: Python build
on:
  repository_dispatch:
    types: trigger-ga___python.yml
permissions:
  contents: read
